# HACKNY-F2019
## ASL-Translator
### Team members: Jiale Qiu, Jagnaudh Bhatia, Joanne Fung, Xuejin Gao

## Inspiration
Inspiration for our project was to find a user-friendly and intuitive way for people to comprehend and translate American Sign Language to English words

## What it does
The web-application uses Machine Learning techniques to detect and classify American Sign Language to English Alphabet with 90% accuracy. 

## How we built it
In the Google Cloud Platform, we uploaded a dataset of different signs in ASL corresponding to each letter in the alphabet. We created this by using Google AutoML Vision, which allowed to create a customized Machine Learning model that we had to train, evaluate, and test, in order to achieve a satisfactory accuracy of predictions.

## Challenges we ran into
We were not able to make our ML model to showcase the predictions in the front-end. We tried to learn how to link the back-end technologies with the front-end, but were unsuccessful in doing so.

## Accomplishments that we're proud of
The model correctly predicted the ASL alphabet letter with an average accuracy of 90%.

## What we learned
Leveraging Google Cloud Platform to build custom Machine Learning Models. 

## What's next for ASL-Translator
Real-time motion-detection for ASL alphabets, allowing easy conversation between American sign language users and non-users of ASL.
